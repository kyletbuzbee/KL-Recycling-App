{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kyletbuzbee/KL-Recycling-App/blob/main/ml_training/notebooks/colab_scrap_metal_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clug_GE-v-ql"
   },
   "source": [
    "# üè≠ KL Recycling: Scrap Metal Weight Prediction Training\n",
    "\n",
    "## Enterprise ML Pipeline for Custom Scrap Metal Detection & Weight Estimation\n",
    "\n",
    "### üöÄ **Ready to train custom ML models for 95%+ accuracy!**\n",
    "\n",
    "**This notebook provides:**\n",
    "- Complete ML training environment in Google Colab\n",
    "- Webcam-based data collection interface\n",
    "- Automated YOLOv8 object detection training\n",
    "- TensorFlow Lite conversion for mobile\n",
    "- Performance monitoring and optimization\n",
    "\n",
    "**Time to completion:** 4-6 weeks | **Target accuracy:** 95%+\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "source": [
    "# üõ†Ô∏è ENVIRONMENT SETUP (Run this first cell)\n",
    "!nvidia-smi\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# Clone and setup project\n",
    "!git clone https://github.com/kyletbuzbee/KL-Recycling-App.git\n",
    "%cd KL-Recycling-App/ml_training\n",
    "\n",
    "# Install dependencies\n",
    "!pip install ultralytics tensorflow pandas matplotlib seaborn opencv-python\n",
    "\n",
    "# Verify setup\n",
    "import torch\n",
    "print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'NONE'}\")\n",
    "print(\"üéâ ML Training Environment Ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_collection"
   },
   "source": [
    "## üì∏ Data Collection (Interactive Camera Interface)\n",
    "\n",
    "**Collect your training data using this webcam interface.**\n",
    "\n",
    "### üìã Guidelines:\n",
    "- üìè Include reference objects (coins, quarters)\n",
    "- üí° Good lighting from multiple angles\n",
    "- üéØ Position scrap metal centrally\n",
    "- üì± Hold camera steady\n",
    "\n",
    "**Target:** 100+ photos per material type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "camera_interface"
   },
   "outputs": [],
   "source": [
    "# Camera capture interface for Colab\n",
    "from IPython.display import display, HTML, Javascript\n",
    "import base64, json, uuid\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# Create data directory\n",
    "data_dir = Path('data/raw_images')\n",
    "for material in ['steel', 'aluminum', 'copper', 'brass']:\n",
    "    (data_dir / material).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# HTML/CSS/JavaScript camera interface\n",
    "camera_interface = '''\n",
    "<div style=\"background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);color:white;padding:25px;border-radius:15px;margin:15px 0;box-shadow:0 8px 32px rgba(0,0,0,0.1);\">\n",
    "  <h2>üì∏ Scrap Metal Training Data Collection</h2>\n",
    "  <p>Collect high-quality training images for your custom ML models</p>\n",
    "\n",
    "  <div style=\"margin:15px 0;font-size:16px;\">\n",
    "    <label style=\"font-weight:bold;margin-right:10px;\">Material:</label>\n",
    "    <select id=\"material\" style=\"padding:8px;border-radius:5px;font-size:16px;\">\n",
    "      <option value=\"steel\">Steel</option>\n",
    "      <option value=\"aluminum\">Aluminum</option>\n",
    "      <option value=\"copper\">Copper</option>\n",
    "      <option value=\"brass\">Brass</option>\n",
    "    </select>\n",
    "  </div>\n",
    "\n",
    "  <button id=\"startBtn\" onclick=\"startCamera()\" style=\"background:#4CAF50;color:white;padding:12px 24px;border:none;border-radius:8px;font-size:16px;margin:5px;cursor:pointer;\">üì∑ Start Camera</button>\n",
    "  <button id=\"captureBtn\" onclick=\"capturePhoto()\" style=\"background:#2196F3;color:white;padding:12px 24px;border:none;border-radius:8px;font-size:16px;margin:5px;cursor:pointer;display:none;\">üì∏ Capture</button>\n",
    "  <button id=\"stopBtn\" onclick=\"stopCamera()\" style=\"background:#f44336;color:white;padding:12px 24px;border:none;border-radius:8px;font-size:16px;margin:5px;cursor:pointer;display:none;\">‚èπÔ∏è Stop</button>\n",
    "\n",
    "  <div id=\"progress\" style=\"margin:15px 0;display:none;\">\n",
    "    <div style=\"width:100%;background:#555;border-radius:15px;overflow:hidden;\">\n",
    "      <div id=\"progressBar\" style=\"width:0%;height:25px;background:linear-gradient(90deg,#00d4aa,#007f73);transition:width 0.3s;\"></div>\n",
    "    </div>\n",
    "    <div id=\"progressText\" style=\"margin-top:8px;font-weight:bold;\">Photos captured: 0/400 total</div>\n",
    "  </div>\n",
    "\n",
    "  <canvas id=\"camera\" style=\"max-width:100%;border:3px solid #fff;border-radius:10px;display:none;margin-top:15px;\"></canvas>\n",
    "</div>\n",
    "\n",
    "<script>\n",
    "let stream, material = 'steel';\n",
    "let counts = {steel:0, aluminum:0, copper:0, brass:0};\n",
    "\n",
    "// Material selection\n",
    "document.getElementById('material').onchange = (e) => material = e.target.value;\n",
    "\n",
    "function startCamera() {\n",
    "  navigator.mediaDevices.getUserMedia({video: {width: 640, height: 480}})\n",
    "    .then(function(mediaStream) {\n",
    "      stream = mediaStream;\n",
    "      const canvas = document.getElementById('camera');\n",
    "      canvas.style.display = 'block';\n",
    "      const ctx = canvas.getContext('2d');\n",
    "      const video = document.createElement('video');\n",
    "      video.srcObject = stream;\n",
    "      video.play();\n",
    "\n",
    "      function draw() {\n",
    "        ctx.drawImage(video, 0, 0, 640, 480);\n",
    "        // Draw guide rectangle\n",
    "        ctx.strokeStyle = '#00ff00';\n",
    "        ctx.lineWidth = 3;\n",
    "        ctx.strokeRect(80, 60, 480, 360);\n",
    "        setTimeout(draw, 33); // ~30fps\n",
    "      }\n",
    "      draw();\n",
    "\n",
    "      document.getElementById('startBtn').style.display = 'none';\n",
    "      document.getElementById('captureBtn').style.display = 'inline-block';\n",
    "      document.getElementById('stopBtn').style.display = 'inline-block';\n",
    "      document.getElementById('progress').style.display = 'block';\n",
    "    })\n",
    "    .catch(function(err) {\n",
    "      alert('Camera error: ' + err.message);\n",
    "    });\n",
    "}\n",
    "\n",
    "function capturePhoto() {\n",
    "  const canvas = document.getElementById('camera');\n",
    "  const dataUrl = canvas.toDataURL('image/jpeg', 0.95);\n",
    "  google.colab.kernel.invokeFunction('notebook_save_photo', [material, dataUrl], {});\n",
    "  counts[material]++;\n",
    "  updateProgress();\n",
    "}\n",
    "\n",
    "function stopCamera() {\n",
    "  if (stream) {\n",
    "    stream.getTracks().forEach(track => track.stop());\n",
    "  }\n",
    "  document.getElementById('camera').style.display = 'none';\n",
    "  document.getElementById('startBtn').style.display = 'inline-block';\n",
    "  document.getElementById('captureBtn').style.display = 'none';\n",
    "  document.getElementById('stopBtn').style.display = 'none';\n",
    "  document.getElementById('progress').style.display = 'none';\n",
    "}\n",
    "\n",
    "function updateProgress() {\n",
    "  const total = Object.values(counts).reduce((a,b)=>a+b,0);\n",
    "  const percent = Math.min((total/400)*100, 100);\n",
    "  document.getElementById('progressBar').style.width = percent + '%';\n",
    "  document.getElementById('progressText').innerHTML = \n",
    "    `<strong>${counts.steel} steel, ${counts.aluminum} aluminum, ${counts.copper} copper, ${counts.brass} brass = ${total}/400 photos</strong>`;\n",
    "}\n",
    "</script>\n",
    "'''\n",
    "\n",
    "display(HTML(camera_interface))\n",
    "\n",
    "# Photo saving callback\n",
    "def notebook_save_photo(material, data_url):\n",
    "    try:\n",
    "        # Decode base64\n",
    "        header, encoded = data_url.split(',')\n",
    "        img_data = base64.b64decode(encoded)\n",
    "\n",
    "        # Generate filename\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        uid = uuid.uuid4().hex[:8]\n",
    "        filename = f\"{material}_{timestamp}_{uid}.jpg\"\n",
    "\n",
    "        # Save image\n",
    "        filepath = data_dir / material / filename\n",
    "        with open(filepath, 'wb') as f:\n",
    "            f.write(img_data)\n",
    "\n",
    "        # Create annotation\n",
    "        weight_ranges = {'steel':(5,50), 'aluminum':(2,20), 'copper':(3,30), 'brass':(4,25)}\n",
    "        weight = round(np.random.uniform(*weight_ranges[material]), 2)\n",
    "\n",
    "        annotation = {\n",
    "            'filename': filename,\n",
    "            'material_type': material,\n",
    "            'weight_pounds': weight,\n",
    "            'bounding_box': [80, 60, 480, 360],  # Default guide rectangle\n",
    "            'confidence': 1.0,\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "        }\n",
    "\n",
    "        # Save annotation\n",
    "        annotation_path = filepath.with_suffix('.json')\n",
    "        with open(annotation_path, 'w') as f:\n",
    "            json.dump(annotation, f, indent=2)\n",
    "\n",
    "        print(f\"‚úÖ Saved {material}: {filename} ({weight:.1f} lbs)\")\n",
    "        return \"Saved\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return \"Error\"\n",
    "\n",
    "# Register callback\n",
    "from google.colab import output\n",
    "output.register_callback('notebook_save_photo', notebook_save_photo)\n",
    "\n",
    "print(\"üéØ Ready to collect training data!\")\n",
    "print(\"Target: 100 photos per material type with reference objects\")\n",
    "print(\"üìä Progress will update as you capture photos\")"
   ],
   "cell_type": "markdown",
   "metadata": {
    "id": "training"
   },
   "source": [
    "## üéØ Start Training Your Custom Model\n",
    "\n",
    "            \n",
    "            const video = document.createElement('video');\n",
    "            video.srcObject = stream;\n",
    "            video.play();\n",
    "            \n",
    "            // Draw live video feed\n",
    "            function drawVideo() {\n",
    "                ctx.drawImage(video, 0, 0);\n",
    "                \n",
    "                // Draw framing guide\n",
    "                ctx.strokeStyle = '#00FF00';\n",
    "                ctx.lineWidth = 2;\n",
    "                ctx.strokeRect(50, 50, 540, 380);\n",
    "                \n",
    "                // Draw crosshair\n",
    "                ctx.strokeStyle = '#FF0000';\n",
    "                ctx.beginPath();\n",
    "                ctx.moveTo(320, 0);\n",
    "                ctx.lineTo(320, 480);\n",
    "                ctx.moveTo(0, 240);\n",
    "                ctx.lineTo(640, 240);\n",
    "                ctx.stroke();\n",
    "                \n",
    "                requestAnimationFrame(drawVideo);\n",
    "            }\n",
    "            \n",
    "            drawVideo();\n",
    "            \n",
    "            document.getElementById('start-camera').style.display = 'none';\n",
    "            document.getElementById('capture').style.display = 'inline-block';\n",
    "            document.getElementById('stop').style.display = 'inline-block';\n",
    "            document.getElementById('progress').style.display = 'block';\n",
    "            \n",
    "        } catch (err) {\n",
    "            alert('Error accessing camera: ' + err.message);\n",
    "        }\n",
    "    });\n",
    "\n",
    "    document.getElementById('capture').addEventListener('click', () => {\n",
    "        const canvas = document.getElementById('canvas');\n",
    "        const dataUrl = canvas.toDataURL('image/jpeg', 0.9);\n",
    "        \n",
    "        // Send to Python backend\n",
    "        google.colab.kernel.invokeFunction('save_photo', [material, dataUrl], {});\n",
    "        \n",
    "        photoCount[material]++;\n",
    "        updateProgress();\n",
    "        \n",
    "        // Visual feedback\n",
    "        const button = document.getElementById('capture');\n",
    "        button.textContent = '‚úÖ Saved!';\n",
    "        button.style.background = '#4CAF50';\n",
    "        setTimeout(() => {\n",
    "            button.textContent = 'üì∏ Capture';\n",
    "            button.style.background = '#2196F3';\n",
    "        }, 1000);\n",
    "    });\n",
    "\n",
    "    document.getElementById('stop').addEventListener('click', () => {\n",
    "        if (stream) {\n",
    "            stream.getTracks().forEach(track => track.stop());\n",
    "        }\n",
    "        \n",
    "        document.getElementById('canvas').style.display = 'none';\n",
    "        document.getElementById('start-camera').style.display = 'inline-block';\n",
    "        document.getElementById('capture').style.display = 'none';\n",
    "        document.getElementById('stop').style.display = 'none';\n",
    "    });\n",
    "\n",
    "    function updateProgress() {\n",
    "        const total = photoCount.steel + photoCount.aluminum + photoCount.copper + photoCount.brass;\n",
    "        const target = Object.keys(photoCount).length * 100;  // 100 photos per material\n",
    "        const percent = (total / target) * 100;\n",
    "        \n",
    "        document.getElementById('progress-bar').style.width = percent + '%';\n",
    "        document.getElementById('progress-text').textContent = \n",
    "            `Photos captured: ${total} / ${target} (${photoCount[material]} for ${material})`;\n",
    "            \n",
    "        // Color coding\n",
    "        const bar = document.getElementById('progress-bar');\n",
    "        if (percent < 25) bar.style.background = '#f44336';\n",
    "        else if (percent < 50) bar.style.background = '#ff9800';\n",
    "        else if (percent < 75) bar.style.background = '#2196F3';\n",
    "        else bar.style.background = '#4CAF50';\n",
    "    }\n",
    "</script>\n",
    "\"\"\"\n",
    "\n",
    "# Display camera interface\n",
    "display(HTML(camera_html))\n",
    "\n",
    "# Callback function to save photos\n",
    "def save_photo(material, data_url):\n",
    "    \"\"\"Save captured photo to data directory.\"\"\"\n",
    "    try:\n",
    "        # Decode base64 image\n",
    "        header, data = data_url.split(\",\")\n",
    "        image_data = base64.b64decode(data)\n",
    "        \n",
    "        # Generate filename\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        filename = f\"{material}_{timestamp}_{uuid.uuid4().hex[:8]}.jpg\"\n",
    "        filepath = data_dir / material / filename\n",
    "        \n",
    "        # Save image\n",
    "        with open(filepath, 'wb') as f:\n",
    "            f.write(image_data)\n",
    "        \n",
    "        # Create dummy annotation for now (weight would be manual entry)\n",
    "        if material == 'steel':\n",
    "            weight = np.random.uniform(5, 50)  # lbs\n",
    "        elif material == 'aluminum':\n",
    "            weight = np.random.uniform(2, 20)\n",
    "        elif material == 'copper':\n",
    "            weight = np.random.uniform(3, 30)\n",
    "        elif material == 'brass':\n",
    "            weight = np.random.uniform(4, 25)\n",
    "        \n",
    "        annotation = {\n",
    "            'filename': filename,\n",
    "            'material_type': material,\n",
    "            'weight_pounds': round(weight, 2),\n",
    "            'bounding_box': [50, 50, 200, 150],  # dummy bbox\n",
    "            'confidence': 0.9,\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'has_reference_object': True,\n",
    "            'collected_in_colab': True\n",
    "        }\n",
    "        \n",
    "        annotation_file = filepath.with_suffix('.json')\n",
    "        with open(annotation_file, 'w') as f:\n",
    "            json.dump(annotation, f, indent=2)\n",
    "        \n",
    "        print(f\"üì∏ Saved {material} photo: {filename} (Estimated weight: {weight:.1f} lbs)\")\n",
    "        \n",
    "        return f\"Photo saved: {filename}\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error saving photo: {e}\")\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Register callback\n",
    "from google.colab import output\n",
    "output.register_callback('save_photo', save_photo)\n",
    "\n",
    "print(\"üì∏ Camera collection interface ready!\")\n",
    "print(\"üéØ Target: 100+ photos per material type with reference objects\")\n",
    "print(\"üí° Tip: Include coins/quarters as reference for accurate scaling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gIttsQQg2WVq"
   },
   "source": [
    "## üìä Data Processing & Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JbE44gze2WVq"
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scripts.data_processor import ScrapMetalDataProcessor\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "\n",
    "# Process collected data\n",
    "processor = ScrapMetalDataProcessor()\n",
    "\n",
    "print(\"üìä Analyzing collected data...\")\n",
    "\n",
    "# Check what's been collected\n",
    "collected_data = []\n",
    "\n",
    "if data_dir.exists():\n",
    "    for material_dir in data_dir.iterdir():\n",
    "        if material_dir.is_dir():\n",
    "            material = material_dir.name\n",
    "            images = list(material_dir.glob(\"*.jpg\"))\n",
    "            annotations = list(material_dir.glob(\"*.json\"))\n",
    "            \n",
    "            print(f\"{material}: {len(images)} images, {len(annotations)} annotations\")\n",
    "            \n",
    "            collected_data.extend([\n",
    "                {\n",
    "                    'material': material,\n",
    "                    'image_path': str(img),\n",
    "                    'annotation_path': str(img.with_suffix('.json'))\n",
    "                }\n",
    "                for img in images\n",
    "            ])\n",
    "\n",
    "print(f\"\\nüìà Total collected: {len(collected_data)} samples\")\n",
    "\n",
    "# Process into training format\n",
    "if len(collected_data) > 10:\n",
    "    print(\"üîÑ Processing data into training format...\")\n",
    "    \n",
    "    # Create data splits\n",
    "    df = pd.DataFrame(collected_data)\n",
    "    \n",
    "    if len(df['material'].unique()) >= 2:\n",
    "        train_df, temp_df = train_test_split(df, train_size=0.7, stratify=df['material'], random_state=42)\n",
    "        val_df, test_df = train_test_split(temp_df, train_size=0.5, stratify=temp_df['material'], random_state=42)\n",
    "        \n",
    "        print(f\"Train: {len(train_df)}, Validation: {len(val_df)}, Test: {len(test_df)}\")\n",
    "        \n",
    "        # Save splits\n",
    "        for split_name, split_df in [('train', train_df), ('val', val_df), ('test', test_df)]:\n",
    "            split_dir = Path(f\"data/scrap_dataset/{split_name}\")\n",
    "            split_dir.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            for _, row in split_df.iterrows():\n",
    "                # Copy image\n",
    "                img_dst = split_dir / Path(row['image_path']).name\n",
    "                shutil.copy2(row['image_path'], img_dst)\n",
    "                \n",
    "                # Copy annotation\n",
    "                ann_dst = img_dst.with_suffix('.json')\n",
    "                if os.path.exists(row['annotation_path']):\n",
    "                    shutil.copy2(row['annotation_path'], ann_dst)\n",
    "        \n",
    "        print(\"‚úÖ Data splits created!\")\n",
    "        \n",
    "        # Data visualization\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        # Material distribution\n",
    "        plt.subplot(2, 2, 1)\n",
    "        df['material'].value_counts().plot(kind='bar', color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A'])\n",
    "        plt.title('Material Distribution')\n",
    "        plt.xlabel('Material')\n",
    "        plt.ylabel('Count')\n",
    "        \n",
    "        # Sample images display (if any exist)\n",
    "        plt.subplot(2, 2, 2)\n",
    "        if len(collected_data) > 0:\n",
    "            sample_img_path = collected_data[0]['image_path']\n",
    "            if os.path.exists(sample_img_path):\n",
    "                sample_img = plt.imread(sample_img_path)\n",
    "                plt.imshow(sample_img)\n",
    "                plt.title('Sample Training Image')\n",
    "                plt.axis('off')\n",
    "        \n",
    "        # Quality scores (if available)\n",
    "        plt.subplot(2, 2, 3)\n",
    "        # Quality analysis would go here\n",
    "        plt.text(0.5, 0.5, 'Quality Analysis\\n(More data needed)', \n",
    "                ha='center', va='center', fontsize=12)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Data preparation status\n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.text(0.5, 0.5, f'Training Ready!\\n{len(train_df)} samples\\n{len(val_df)} validation',\n",
    "                ha='center', va='center', fontsize=14, color='green')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Need more data from different materials for proper training\")\n",
    "        \n",
    "else:\n",
    "    print(\"üì∏ No data collected yet. Use the camera interface above to collect training images first.\")\n",
    "    print(\"Recommended: 100+ images per material type (steel, aluminum, copper, brass)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fq_kcNi2WVs"
   },
   "source": [
    "## ü§ñ Model Training - YOLOv8 Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GdTSjgFW2WVs"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "# Check for training data\n",
    "data_yaml_path = Path('data/scrap_dataset/data.yaml')\n",
    "\n",
    "if not data_yaml_path.exists():\n",
    "    print(\"‚ö†Ô∏è Creating data configuration for YOLO training...\")\n",
    "    \n",
    "    # Create minimal data.yaml if missing\n",
    "    data_config = {\n",
    "        'path': './data/scrap_dataset',\n",
    "        'train': 'train',\n",
    "        'val': 'val',\n",
    "        'test': 'test',\n",
    "        'names': {\n",
    "            0: 'steel',\n",
    "            1: 'aluminum',\n",
    "            2: 'copper',\n",
    "            3: 'brass'\n",
    "        },\n",
    "        'nc': 4\n",
    "    }\n",
    "    \n",
    "    with open(data_yaml_path, 'w') as f:\n",
    "        yaml.dump(data_config, f, default_flow_style=False)\n",
    "    \n",
    "    print(f\"‚úÖ Created {data_yaml_path}\")\n",
    "\n",
    "print(\"üöÄ Starting YOLOv8 training...\")\n",
    "print(\"‚è∞ Expected time: 30-120 minutes depending on data size\")\n",
    "print(\"üéØ Target: 90%+ mAP for scrap metal detection\")\n",
    "\n",
    "# Load pre-trained YOLOv8 model\n",
    "model = YOLO('yolov8m.pt')  # Medium model with good balance\n",
    "\n",
    "# Training configuration optimized for Colab\n",
    "training_results = model.train(\n",
    "    data='data/scrap_dataset/data.yaml',\n",
    "    epochs=50,  # Reduced for demo, increase to 100+ for production\n",
    "    batch=8,    # Colab GPU memory friendly\n",
    "    imgsz=640,  # Input image size\n",
    "    optimizer='Adam',  # GPU-optimized\n",
    "    lr0=0.001,  # Learning rate\n",
    "    weight_decay=0.0005,\n",
    "    momentum=0.937,\n",
    "    # Data augmentation\n",
    "    augment=True,\n",
    "    mosaic=1.0,   # Enable mosaic augmentation\n",
    "    mixup=0.1,    # Enable mixup\n",
    "    # Regularization\n",
    "    label_smoothing=0.1,\n",
    "    # Project
